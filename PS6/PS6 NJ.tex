\documentclass[]{article}
\usepackage{amsmath, amsfonts}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage[headsep=.2in]{geometry}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{color}
\usepackage{soul}
\usepackage{multirow}
\usepackage{float}
\usepackage{pgfplots}	% To draw charts directly in Latex
\usepackage{marvosym}	% For lightning symbol to denote contradiction
\usepackage{cleveref}	% For clever referencing :)
\usepackage{nameref}	% For referencing to the section name, not number
\usepackage{slashbox}	% For putting a backslash in the table for players

%TikZ package for drawing:
\usepackage{tikz}
%For calculation of coordinates:
\usetikzlibrary{calc}
\usetikzlibrary{positioning}

%opening
\title{Problem Set VI \\ \large Microeconomics II}
\author{Nurfatima Jandarova}
\date{\today}
\pagestyle{fancy}

\lhead{Microeconomics II, Problem Set VI}
\rhead{Nurfatima Jandarova}
\renewcommand{\headrulewidth}{0.4pt}
\fancyheadoffset{1 cm}

\geometry{a4paper, left=20mm, top=20mm, bottom = 20mm, headheight=8mm}

\sloppy
\definecolor{lightgray}{gray}{0.5}
\setlength{\parindent}{0pt}

\renewcommand{\arraystretch}{1.3}

\setul{0.2ex}{0.2ex}
\setulcolor{red}

% Define a checkmark
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} 

\begin{document}

\maketitle

\subsection*{Exercise 1}

The set of NE in pure strategies is $\{(M, l), (L, r)\}$.

\begin{enumerate}
	\item $\gamma_1 = (0, 1, 0), \gamma_2 = (1, 0)$
	Define $\gamma_{1k} = (\rho\varepsilon_{1k}, 1 - (1 + \rho)\varepsilon_{1k}, \varepsilon_{1k}), \gamma_{2k} = (1 - \varepsilon_{2k}, \varepsilon_{2k})$ such that $\lim\limits_{k\to\infty}\varepsilon_{1k} = \lim\limits_{k\to\infty}\varepsilon_{2k} = 0$, for some $\rho > 0$.
	
	Then, induced belief system is $\mu_{2k} = (\frac{1 - (1 + \rho)\varepsilon_{1k}}{1 - \rho\varepsilon_{1k}}, \frac{\varepsilon_{1k}}{1 - \rho\varepsilon_{1k}}) \to (1, 0)$ as $k\to\infty$.
	
	Given the belief system $\mu_2 = (1, 0)$, player 2 prefers to choose $l$ and player 1's best response then is to choose $M$. Hence, $(\gamma_1, \gamma_2) = ((0, 1, 0), (1, 0))$ and $\mu_2 = (1, 0)$ constitute a sequential equilibrium.
	
	\item $\gamma_1 = (1, 0, 0)$ and $\gamma_2 = (0, 1)$. Define $\gamma_{1k} = (1 - (1 + \rho)\varepsilon_{1k}, \rho\varepsilon_{1k}, \varepsilon_{1k}), \gamma_{2k} = (\varepsilon_{2k}, 1 - \varepsilon_{2k})$, where $\lim\limits_{k\to\infty}\varepsilon_{1k} = \lim\limits_{k\to\infty}\varepsilon_{2k} = 0$, for some $\rho > 0$.
	
	Induced belief system is $\mu_{2k} = (\frac{\rho\varepsilon_{1k}}{(1 + \rho)\varepsilon_{1k}}, \frac{\varepsilon_{1k}}{(1 + \rho)\varepsilon_{1k}}) = (\frac{\rho}{1 + \rho}, \frac{1}{1 + \rho}) \to (\frac{\rho}{1 + \rho}, \frac{1}{1 + \rho})$ as $k\to\infty$.
	\begin{equation}
		\begin{split}
			\pi_2(l|\mu_2, H_2) = \frac{\rho}{1 + \rho} \leq \pi_2(r|\mu_2, H_2) = \frac{1}{1 + \rho} \iff \rho\leq 1 \nonumber
		\end{split}
	\end{equation}
	Then, player 1's best response is to play $L$. Therefore, $(\gamma_1, \gamma_2) = ((1, 0, 0), (0, 1))$ and any belief system $\mu_2 = (\frac{\rho}{1 + \rho}, \frac{1}{1 + \rho})$ such that $\rho\in(0, 1]$ is a sequential equilibrium given.
	
	\item $\gamma_1 = (1, 0, 0)$ and $\gamma_2 = (q, 1 - q), \forall q\in[0, 1]$. Define $\gamma_{1k} = (1 - 2\varepsilon_{1k}, \varepsilon_{1k}, \varepsilon_{1k}), \gamma_{2k} = (q, 1 - q)$, where $\lim\limits_{k\to\infty}\varepsilon_{1k} = 0$.
	
	Induced belief system is $\mu_{2k} = (\frac{1}{2}, \frac{1}{2}) \to (\frac{1}{2}, \frac{1}{2})$ as $k\to\infty$.
	\begin{equation}
		\begin{split}
			\pi_2(l|\mu_2, H_2) = \frac{1}{2} = \pi_2(r|\mu_2, H_2) \nonumber
		\end{split}
	\end{equation}
	Hence, $\gamma_2 = (q, 1 - q)$ is optimal for player 2 in his information set given the belief system $\mu_2 = (\frac{1}{2}, \frac{1}{2})$. Let's compare payoff of player 1 following strategy $\gamma_1$ and deviating to strategy $\hat{\gamma_1} = (1 - \nu, \nu, 0)$ for some $\nu > 0$:
	\begin{equation}
		\begin{split}
			\pi_1(\gamma_1, \gamma_2|\mu_2) = 2 \geq 2 - \nu(1 - 2q) = \pi_1(\hat{\gamma_1}, \gamma_2|\mu_2) \iff q \leq\frac{1}{2} \nonumber
		\end{split}
	\end{equation}
	Hence, all strategy profiles $(\gamma_1 = (1, 0, 0), \gamma_2 = (q, 1 - q)), \forall q\leq\frac{1}{2}$ given the belief system $\mu_2 = (\frac{1}{2}, \frac{1}{2})$ constitute sequential equilibria.
\end{enumerate}

\subsubsection*{Exercise 2}

Let's first find all NE in pure strategies. From \Cref{tab:ex2str}, we can see that the set of NE in pure strategies is $\{(M, r, a), (R, l, a)\}$.

\begin{table}[h]
	\centering
	\begin{minipage}{0.49\linewidth}
		\centering
		Player 3 plays $a$ \\
		\begin{tabular}{c|cc}
			\backslashbox{1}{2} & $l$ & $r$ \\\hline
			L & (0, \ul{1}, \ul{0}) & (0, 0, \ul{0}) \\
			M & (0, 1, \ul{1}) & (\ul{2}, \ul{2}, \ul{1}) \\
			R & (\ul{1}, \ul{0}, \ul{0}) & (1, \ul{0}, \ul{0})
		\end{tabular}
	\end{minipage}
	\begin{minipage}{0.49\linewidth}
		\centering
		Player 3 plays $b$ \\
		\begin{tabular}{c|cc}
			\backslashbox{1}{2} & $l$ & $r$ \\\hline
			L & (0, \ul{1}, \ul{0}) & (0, 0, \ul{0}) \\
			M & (0, \ul{1}, 0) & (0, 0, 0) \\
			R & (\ul{1}, 0, \ul{0}) & (\ul{1}, 0, \ul{0})
		\end{tabular}
	\end{minipage}
	\caption{Strategic form of the game}
	\label{tab:ex2str}
\end{table}

\begin{itemize}
	\item[$(M, r, a)$] Define completely mixed strategies of players $\gamma_{1k} = (\rho\varepsilon_{1k}, 1 - (1 + \rho)\varepsilon_{1k}, \varepsilon_{1k}), \gamma_{2k} = (\varepsilon_{2k}, 1 - \varepsilon_{2k}), \gamma_{3k} = (1 - \varepsilon_{3k}, \varepsilon_{3k})$ for some $\rho > 0$ such that $\varepsilon_{sk}\underset{k\to\infty}{\longrightarrow}0, \forall s\in\{1,2,3\}$. Thus, $\lim\limits_{k\to\infty}\gamma_{1k} = (0, 1, 0), \lim\limits_{k\to\infty}\gamma_{2k} = (0, 1), \lim\limits_{k\to\infty}\gamma_{3k} = (1, 0)$.
	
	These strategies induce the following beliefs:
	\begin{equation}
		\begin{split}
			\mu_{2k} = (\frac{\rho\varepsilon_{1k}}{1 - \varepsilon_{1k}}, \frac{1 - (1 + \rho)\varepsilon_{1k}}{1 - \varepsilon_{1k}}) \underset{k\to\infty}{\longrightarrow} (0, 1) = \mu_2 \\ \nonumber
			\mu_{3k} = (\varepsilon_{2k}, 1 - \varepsilon_{2k}) \underset{k\to\infty}{\longrightarrow} (0, 1) = \mu_3 
		\end{split}
	\end{equation}
	
	Given this belief system
	\begin{equation}
		\begin{split}
			\pi_3(a|\mu_2, \mu_3, H_3) = 1 > 0 = \pi_3(b|\mu_2, \mu_3, H_3) &\Rightarrow \gamma_3^* = (1, 0) \\ \nonumber
			\pi_2((l, a)|\mu_2, \mu_3, H_2) = 1 < 2 = \pi_2((r, a)|\mu_2, \mu_3, H_2) &\Rightarrow \gamma_2^* = (0, 1) \\
			\begin{cases}
			\pi_1((L, r, a)|\mu_2, \mu_3, H_1) = 0 < 2 = \pi_1((M, r, a)|\mu_2, \mu_3, H_1) \\
			\pi_1((M, r, a)|\mu_2, \mu_3, H_1) = 2 > 1 = \pi_1((R, r, a)|\mu_2, \mu_3, H_1)
			\end{cases} &\Rightarrow \gamma_1^* = (0, 1, 0)
		\end{split}
	\end{equation}
	Hence, a strategy profile $\gamma^* = (\gamma_1^*, \gamma_2^*, \gamma_3^*)$ and a belief system $\mu^* = (\mu_2, \mu_3)$ is a sequential equilibrium.
	
	\item[$(R, l, a)$] Define completely mixed strategies of players $\gamma_{1k} = (\rho\varepsilon_{1k}, \varepsilon_{1k}, 1 - (1 + \rho)\varepsilon_{1k}), \gamma_{2k} = (1 - \varepsilon_{2k}, \varepsilon_{2k}), \gamma_{3k} = (1 - \varepsilon_{3k}, \varepsilon_{3k})$ for some $\rho > 0$ such that $\varepsilon_{sk}\underset{k\to\infty}{\longrightarrow}0, \forall s\in\{1,2,3\}$. Thus, $\lim\limits_{k\to\infty}\gamma_{1k} = (0, 0, 1), \lim\limits_{k\to\infty}\gamma_{2k} = (1, 0), \lim\limits_{k\to\infty}\gamma_{3k} = (1, 0)$.
	
	These strategies induce following beliefs:
	\begin{equation}
		\begin{split}
			\mu_{2k} = (\frac{\rho}{1 + \rho}, \frac{1}{1 + \rho}) \underset{k\to\infty}{\longrightarrow} (\frac{\rho}{1 + \rho}, \frac{1}{1 + \rho}) = \mu_2 \\ \nonumber
			\mu_{3k} = (1 - \varepsilon_{2k}, \varepsilon_{2k}) \underset{k\to\infty}{\longrightarrow} (1, 0) = \mu_3
		\end{split}
	\end{equation}
	
	Given this belief system
	\begin{equation}
		\begin{split}
			\pi_3(a|\mu_2, \mu_3, H_3) = 1 > 0 = \pi_3(b|\mu_2, \mu_3, H_3) &\Rightarrow \gamma_3^* = (1, 0) \\ \nonumber
			\pi_2((l, a)|\mu_2, \mu_3, H_2) = 1 > \frac{2}{1 + \rho} = \pi_2((r, a)|\mu_2, \mu_3, H_2) &\Rightarrow \gamma_2^* = (1, 0) \iff \rho > 1 \\
			\pi_1((L, l, a)|\mu_2, \mu_3, H_1) = \pi_1((M, l, a)|\mu_2, \mu_3, H_1) = 0 < 1 = \pi_1((R, l, a)|\mu_2, \mu_3, H_1)
			 &\Rightarrow \gamma_1^* = (0, 0, 1) \iff \rho > 1
		\end{split}
	\end{equation}
	
	Hence, a strategy profile $\gamma^* = (\gamma_1^*, \gamma_2^*, \gamma_3^*)$ and a belief system $\mu^* = (\mu_2, \mu_3)$ such that $\rho > 1$ is another sequential equilibrium.
\end{itemize}

\subsection*{Exercise 3}

The game could be formalized as a Bayesian game $BG = \{N, T, A, P, \{\pi_i\}_{i\in N}\}$, where
\begin{itemize}[label={}]
	\item $N = \{1, 2\}$;
	\item $T = T_1\times T_2 = \{b_1, b_2\}\times\{t_2\}$, where $b_1$ refers to the first box and $b_2$ refers to the second box (notice that there's only one type of player 2);
	\item $A = \{A, B\}\times\{C, D\}$;
	\item $P: T \to [0, 1], \begin{matrix}
	(b_1, t_2) \mapsto \frac{1}{2} \\
	(b_2, t_2) \mapsto \frac{1}{2} \\
	\end{matrix}$;
	\item $\pi_i: T\times A\to \mathbb{R}$ specified by the table in the problem.
\end{itemize}

Suppose player 2 thinks that player 1's strategy is $\gamma_1(b_1) = (p_1, 1 - p_1)$ and $\gamma_1(b_2) = (p_2, 1 - p_2)$. Then,
\begin{equation}
	\begin{split}
		\mathbb{E}\pi_2(C)& = \frac{1}{2}[\pi_2((b_1, t_2), \gamma_1(b_1), C) + \pi_2((b_2, t_2), \gamma_1(b_2), C)] = \frac{1}{2}(p_1 + 2p_2 + 1 - p_2) = \frac{1}{2}(1 + p_1 + p_2) \\ \nonumber
		\mathbb{E}\pi_2(D)& = \frac{1}{2}[\pi_2((b_1, t_2), \gamma_1(b_1), D) + \pi_2((b_2, t_2), \gamma_1(b_2), D)] = \frac{1}{2}(4p_2 + 3(1 - p_2)) = \frac{1}{2}(3 + p_2) \\
		\mathbb{E}\pi_2(D) - \mathbb{E}\pi_2(C)& = \frac{1}{2}(3 + p_2 - 1 - p_1 - p_2) = \frac{1}{2}(2 - p_1) > 0, \forall p_1\in[0, 1], \forall p_2\in[0, 1]
	\end{split}
\end{equation}
Hence, player 2 maximizes expected payoff by choosing $D$ and $\gamma_2^* = (0, 1)$.

Then, player 1 makes decision based on
\begin{equation}
	\begin{split}
		\frac{1}{2}[\pi_1((b_1, t_2), A, \gamma_2^*) + \pi_1((b_2, t_2), A, \gamma_2^*)] = 0 < \frac{1}{2} = \frac{1}{2}[\pi_1((b_1, t_2), B, \gamma_2^*) + \pi_1((b_2, t_2), B, \gamma_2^*)] \Rightarrow\gamma_1^* = (0, 1)\nonumber
	\end{split}
\end{equation}

Therefore, a strategy profile $\gamma^* = \{\gamma_1^*, \gamma_2^*\}$ is a BNE in pure strategies.

\subsection*{Exercise 4}

The game could be described as a Bayesian game $BG = \{N, T, A, P, \{\pi_i\}_{i\in N}\}$, where
\begin{itemize}[label={}]
	\item $N = \{1, 2\}$;
	\item $T = T_1\times T_2 = \{c^h, c^l\}^2$;
	\item $A = \mathbb{R}_+^2$;
	\item \begin{flalign}
			P: T &\to [0, 1] && \nonumber\\
			(c^h, c^h) &\mapsto p^2 \nonumber\\
			(c^h, c^l) &\mapsto p(1 - p) \nonumber\\
			(c^l, c^h) &\mapsto (1 - p)p \nonumber\\
			(c^l, c^l) &\mapsto (1 - p)^2\nonumber
	\end{flalign}
	\item \begin{flalign}
			\pi_i: T\times A&\to \mathbb{R}  \nonumber\\
			(t_i, t_j, q_i, q_j)&\mapsto\max\{M - d(q_i + q_j), 0\}q_i - t_iq_i, \qquad\forall i\in N &&\nonumber
	\end{flalign}
	where $t_i\in T_i, \forall i\in N$ is a generic notation for a realization of the type of any player $i$ and $q_i$ is a typical element of $A_i$.
\end{itemize}
Since both firms could either be of high or low type and each firm only knows its own marginal cost, the equilibrium is symmetric, i.e., only depends on the realization of the type rather than the individual firm. Define strategy of each type of the firm as $\gamma_i:T_i\to\mathbb{R+}, c^h \mapsto q_i^h, c^l \mapsto q_i^l, \forall i\in N$. And in the equilibrium $q_1^h = q_2^h$ and $q_1^l = q_2^l$ hold.

\begin{equation}
	\begin{split}
		\max\limits_{q_i^h}&\quad\pi_i(q_i^h, \gamma_j|t_i = c^h)=\max\{M - d[q_i^h + pq_j^h + (1 - p)q_j^l], 0\}q_i^h - c^hq_i^h\nonumber \text{ s.t. }q_i^h\geq 0, \qquad\forall i\in N\\
		\mathcal{L}_i^h& = (M - d[q_i^h + pq_j^h + (1 - p)q_j^l])q_i^h - c^hq_i^h + \mu(M - d[q_i^h + pq_j^h + (1 - p)q_j^l]) + \lambda q_i^h \\ \nonumber
		&\begin{cases}
			&M - d(1 - p)q_j^l - dpq_j^h - 2dq_i^h - c^h - \mu d + \lambda = 0 \\
			&\min\{\mu, M - d[q_i^h + pq_j^h + (1 - p)q_j^l]\} = 0\\
			&\min\{\lambda, q_i^h\} = 0\\
		\end{cases}
		\intertext{Substitute $q_1^h = q_2^h = q^h$ and $q_1^l = q_2^l = q^l$:}
		&\begin{cases}
			&M - d(1 - p)q^l - c^h - \mu d + \lambda = (2 + p)dq^h \\
			&\min\{\mu, M - d[(1 + p)q^h + (1 - p)q^l]\} = 0\\
			&\min\{\lambda, q^h\} = 0\\
		\end{cases}
		\intertext{Case I: $M - d[(1 + p)q^h + (1 - p)q^l] > 0 \Rightarrow \mu = 0$ and $q^h > 0\Rightarrow\lambda = 0$}
		&M - d(1 - p)q^l - c^h = (2 + p)dq^h \\
		&q^h = \frac{M - d(1 - p)q^l - c^h}{d(2 + p)}\text{ if }M - d(1 - p)q^l - c^h > 0
		\intertext{Case II: $M - d(1 - p)q^l > 0 \Rightarrow \mu = 0$ and $q^h = 0\Rightarrow\lambda \geq 0$}
		&\begin{cases}
			q^h = 0 \\
			M - d(1 - p)q^l - c^h + \lambda = 0
		\end{cases}\begin{cases}
			q^h = 0 \\
			\lambda = c^h -(M - d(1 - p)q^l)
		\end{cases}\text{ if } c^h \geq (M - d(1 - p)q^l)
		\intertext{Case III: $M - d[(1 + p)q^h + (1 - p)q^l] = 0 \Rightarrow \mu \geq 0$ and $q^h > 0 \Rightarrow \lambda = 0$}
		&\begin{cases}
			M - d(1 - p)q^l - c^h - \mu d = (2 + p)dq^h \\
			M - dq^h(1 + p) - d(1 - p)q^l = 0
		\end{cases}\begin{cases}
			\mu = -\frac{M - d(1 - p)q^l}{d(1 + p)} - \frac{c^h}{d} \leq 0 \Rightarrow \text{\Lightning}\\
			q^h = \frac{M - d(1 - p)q^l}{d(1 + p)}
		\end{cases}
		\intertext{Case IV: $M - d(1 - p)q^l = 0 \Rightarrow \mu \geq 0$ and $q^h = 0 \Rightarrow \lambda \geq 0$}
		&\begin{cases}
			q^h = 0 \\
			M - d(1 - p)q^l = 0 \\
			\lambda - \mu d = c^h
		\end{cases}
		\intertext{Hence, the best response correspondence of the high cost firm is}
		&\rho_h(q^l) = \begin{cases}
		\frac{M - d(1 - p)q^l - c^h}{d(2 + p)}&\text{ if }M - d(1 - p)q^l - c^h > 0 \\
		0&\text{ if }c^h \geq M - d(1 - p)q^l > 0 \text{ or } M - d(1 - p)q^l = 0
		\end{cases}
	\end{split}
\end{equation}
Similarly, if the firm has low cost firm
\begin{equation}
	\begin{split}
		\max\limits_{q_i^l}&\quad\pi_i(q_i^l, \gamma_j|t_i = c^l)=\max\{M - d[q_i^l + pq_j^h + (1 - p)q_j^l], 0\}q_i^l - c^lq_i^l\text{ s.t. }q_i^l\geq 0, \qquad\forall i\in N\\
		\mathcal{L}_i^l& = (M - d[q_i^l + pq_j^h + (1 - p)q_j^l])q_i^l - c^lq_i^l + \nu(M - d[q_i^l + pq_j^h + (1 - p)q_j^l]) + \phi q_i^l \\ \nonumber
		&\begin{cases}
			&M - 2dq_i^l - dpq_j^h - d(1 - p)q_j^l - c^l - \nu d + \phi = 0 \\
			&\min\{\nu, M - d[q_i^l + pq_j^h + (1 - p)q_j^l]\} = 0 \\
			&\min\{\phi, q_i^l\} = 0
		\end{cases}
		\intertext{Substitute $q_1^h = q_2^h = q^h$ and $q_1^l = q_2^l = q^l$:}
		&\begin{cases}
			&M - dpq^h - c^l - \nu d + \phi = (3 - p)dq^l \\
			&\min\{\nu, M - d[pq^h + (2 - p)q^l]\} = 0 \\
			&\min\{\phi, q^l\} = 0
		\end{cases}
		\intertext{Case I: $M - dpq^h - d(2 - p)q^l > 0 \Rightarrow \nu = 0$ and $q^l > 0 \Rightarrow \phi = 0$}
		&M - dpq^h - c^l = (3 - p)dq^l \\
		&q^l = \frac{M - dpq^h - c^l}{d(3 - p)}\text{ if }M - dpq^h - c^l > 0
		\intertext{Case II: $M - dpq^h > 0 \Rightarrow \nu = 0$ and $q^l = 0 \Rightarrow \phi \geq 0$}
		&\begin{cases}
			&M - dpq^h - c^l + \phi = 0 \\
			&q^l = 0
		\end{cases}\begin{cases}
			\phi = -(M - dpq^h - c^l)\\
			q^l = 0
		\end{cases}\text{ if }M - dpq^h \leq c^l
		\intertext{Case III: $M - dpq^h - d(2 - p)q^l = 0 \Rightarrow \nu \geq 0$ and $q^l > 0 \Rightarrow \phi = 0$}
		&\begin{cases}
			&M - dpq^h - c^l - \nu d = (3 - p)dq^l \\
			&M - d[pq^h + (2 - p)q^l] = 0 \\
		\end{cases}\begin{cases}
			\nu = -\frac{M - dpq^h}{d(2 - p)} - \frac{c^l}{d} \leq 0\Rightarrow\text{\Lightning}\\
			q^l = \frac{M - dpq^h}{d(2 - p)}
		\end{cases}
		\intertext{Case IV: $M - dpq^h = 0 \Rightarrow \nu \geq 0$ and $q^l = 0 \Rightarrow \phi \geq 0$}
		&\begin{cases}
			&\phi - \nu d = c^l \\
			&M - dpq^h = 0 \\
			&q^l = 0
		\end{cases}
		\intertext{Hence, the best response correspondence of the low cost firm is}
		&\rho_l(q^h) = \begin{cases}
		\frac{M - dpq^h - c^l}{d(3 - p)}&\text{ if }M - dpq^h - c^l > 0 \\
		0&\text{ if }c^l\geq M - dpq^h > 0 \text{ or } M - dpq^h = 0
		\end{cases}
	\end{split}
\end{equation}
So, equilibrium strategy is found at the intersection of the two best responses. Suppose, first, that optimal strategies are interior solutions:
\begin{equation}
	\begin{split}
		q^h& = \frac{M - c^h}{d(2 + p)} - \frac{(1 - p)}{(2 + p)}\Bigg(\frac{M - c^l}{d(3 - p)} - \frac{pq^h }{(3 - p)}\Bigg)^{\footnotemark}\Rightarrow\\\nonumber
		\gamma^*(c^h)& = \frac{2M - (3 - p)c^h + (1 - p)c^l}{6d} \Rightarrow \gamma^*(c^l) = \frac{2M + pc^h - (2 + p)c^l}{6d}
	\end{split}
\end{equation}
\footnotetext{I hope you don't mind that I'm skipping the tedious calculation steps here. If not, I am sorry. I was too lazy to type it all up.}
For these to be optimal strategies the following condition needs to hold:
\begin{equation}
	c^h < \frac{2M + (1 - p)c^l}{3 - p}
\end{equation}
Notice that $\gamma^*(c^l) > 0$ because $2M + pc^h - (2 + p)c^l = 2\underbrace{(M - c^l)}_{>0} + p\underbrace{(c^h - c^l)}_{>0} > 0$.

Suppose there exists an equilibrium such that $q^h = 0, q^l > 0$. From the best response correspondence of low-type firm, we infer that $q^l = \frac{M - c^l}{d(3 - p)}$. Given this strategy, $q^h = 0$ is optimal if\footnote{Strictly speaking, there's another condition. But it holds regardless of the values of the model: $M - (1 - p)\frac{M - c^l}{3 - p} = \frac{2M + (1 - p)c^l}{3 - p} > 0$}
\begin{equation}
	c^h \geq \frac{2M + (1 - p)c^l}{3 - p}
	\label{eq: ex4cornerhc}
\end{equation}
Hence, whenever \eqref{eq: ex4cornerhc} holds, the equiliubrium strategies are $\gamma^*(c^l) = \frac{M - c^l}{d(3 - p)}, \gamma^*(c^h) = 0$.

Suppose there is another equilibrium such that $q^h > 0, q^l = 0$. From the best response of high-cost firm $q^h = \frac{M - c^h}{d(2 + p)}$. Then, $M - p\frac{M - c^h}{2 + p} - c^l = \frac{2(M - c^l) + p(c^h - c^l)}{2 + p} > 0 \Rightarrow q^{l*} = \frac{2(M - c^l) + p(c^h - c^l)}{d(3 - p)(2 + p)}$ \Lightning

Suppose there is an equilibrium such that both $q^h = q^l = 0$. But the best response of the low-cost firm is to set $q^l = \frac{M - c^l}{d(3 - p)} > 0$ \Lightning

Therefore, there are two Bayesian equilibria:
\begin{equation}
	\begin{split}
		&\begin{cases}
			\gamma^*(c^h)& = \frac{2M - (3 - p)c^h + (1 - p)c^l}{6d} \\
			\gamma^*(c^l)& = \frac{2M + pc^h - (2 + p)c^l}{6d}
		\end{cases}\text{ if } c^h < \frac{2M + (1 - p)c^l}{3 - p}\\ \nonumber
		&\begin{cases}
			\gamma^*(c^h)& = 0 \\
			\gamma^*(c^l)& = \frac{M - c^l}{d(3 - p)}
		\end{cases}\text{ if } c^h \geq \frac{2M + (1 - p)c^l}{3 - p}
	\end{split}
\end{equation}

{\huge\textcolor{red}{Dependence on p}}

\subsection*{Exercise 5}

The game could be described as a Bayesian game $BG = \{N, T, A, P, \{\pi_i\}_{i\in N}\}$, where
\begin{itemize}[label={}]
	\item $N = \{1, 2\}$;
	\item $T = V^2 = \{v_0, v_1\}^2$;
	\item $A = \{v_0, v_1, \frac{v_0 + v_1}{2}\}^2$;
	\item $P: T \to [0, 1], \qquad (v, v') \mapsto \frac{1}{4},\forall(v, v')\in V^2$;
	\item $\pi_i: T\times A\to \mathbb{R}$ specified in the \Cref{tab:ex5payoff}.
\end{itemize}

\begin{table}[h]
	\begin{minipage}{0.4\linewidth}
		\begin{tabular}{c|ccc}
			\backslashbox{$v_0$}{$v_0$} & $v_0$ & $v_1$ & $\frac{v_0 + v_1}{2}$ \\\hline
			$v_0$ & (0, 0) & (0, $v_0 - v_1$) & (0, $\frac{v_0 - v_1}{2}$) \\
			$v_1$ & ($v_0 - v_1$, 0) & ($\frac{v_0 - v_1}{2}$, $\frac{v_0 - v_1}{2}$) & ($v_0 - v_1$, 0) \\
			$\frac{v_0 + v_1}{2}$ & ($\frac{v_0 - v_1}{2}$, 0) & (0, $v_0 - v_1$) & ($\frac{v_0 - v_1}{4}$, $\frac{v_0 - v_1}{4}$)
		\end{tabular}
	\end{minipage}\hfill
	\begin{minipage}{0.4\linewidth}
		\begin{tabular}{c|ccc}
			\backslashbox{$v_0$}{$v_1$} & $v_0$ & $v_1$ & $\frac{v_0 + v_1}{2}$ \\\hline
			$v_0$ & (0, $\frac{v_1 - v_0}{2}$) & (0, 0) & (0, $\frac{v_1 - v_0}{2}$) \\
			$v_1$ & ($v_0 - v_1$, 0) & ($\frac{v_0 - v_1}{2}$, 0) & ($v_0 - v_1$, 0) \\
			$\frac{v_0 + v_1}{2}$ & ($\frac{v_0 - v_1}{2}$, 0) & (0, 0) & ($\frac{v_0 - v_1}{4}$, $\frac{v_1 - v_0}{4}$)
		\end{tabular}
	\end{minipage}\\
	\\
	\\
	\begin{minipage}{0.4\linewidth}
		\begin{tabular}{c|ccc}
			\backslashbox{$v_1$}{$v_0$} & $v_0$ & $v_1$ & $\frac{v_0 + v_1}{2}$ \\\hline
			$v_0$ & ($\frac{v_1 - v_0}{2}$, 0) & (0, $v_0 - v_1$) & (0, $\frac{v_0 - v_1}{2}$) \\
			$v_1$ & (0, 0) & (0, $\frac{v_0 - v_1}{2}$) & (0, 0) \\
			$\frac{v_0 + v_1}{2}$ & ($\frac{v_1 - v_0}{2}$, 0) & (0, $v_0 - v_1$) & ($\frac{v_1 - v_0}{4}$, $\frac{v_0 - v_1}{4}$)
		\end{tabular}
	\end{minipage}\hfill
	\begin{minipage}{0.4\linewidth}
		\begin{tabular}{c|ccc}
			\backslashbox{$v_1$}{$v_1$} & $v_0$ & $v_1$ & $\frac{v_0 + v_1}{2}$ \\\hline
			$v_0$ & ($\frac{v_1 - v_0}{2}$, $\frac{v_1 - v_0}{2}$) & (0, 0) & (0, $\frac{v_1 - v_0}{2}$) \\
			$v_1$ & (0, 0) & (0, 0) & (0, 0) \\
			$\frac{v_0 + v_1}{2}$ & ($\frac{v_1 - v_0}{2}$, 0) & (0, 0) & ($\frac{v_1 - v_0}{4}$, $\frac{v_1 - v_0}{4}$)
		\end{tabular}
	\end{minipage}
	\caption{Payoff table}
	\label{tab:ex5payoff}
\end{table}

Notice again that the definition of the game assumes symmetric solution, i.e., it only depends on the type of the buyer, not an individual buyer per se. Define $\forall i\in N$ strategy as $\gamma_i:T_i\to\{v_0, v_1, \frac{v_0 + v_1}{2}\}$. Hence, a strategy profile is $\gamma = (\gamma(v_0), \gamma(v_1))$. Note that $\gamma^*(v_0) = v_0$ is strictly dominant strategy with a payoff of zero regardless of the types of the other player; otherwise, get negative payoff.

Now, suppose $\gamma^*(v_1) = v_0$. Then, $\forall i\in N$ and $j\neq i$
\begin{equation}
	\begin{split}
		\mathbb{E}\pi_i(v_0|t_i = v_1)& = P(t_j = v_0|t_i = v_1)\pi_i(t_j = v_0, v_0, \gamma^*(v_0)|t_i = v_1) + P(t_j = v_1|t_i = v_1)\pi_i(t_j = v_1, v_0, \gamma^*(v_1)|t_i = v_1)\\\nonumber
		& = \frac{1}{2}\frac{v_1 - v_0}{2} + \frac{1}{2}\frac{v_1 - v_0}{2} = \frac{v_1 - v_0}{2}\\
		\mathbb{E}\pi_i({\scriptstyle\frac{v_0 + v_1}{2}}|t_i = v_1)& = P(t_j = v_0|t_i = v_1)\pi_i(t_j = v_0, {\scriptstyle\frac{v_0 + v_1}{2}}, \gamma^*(v_0)|t_i = v_1)\\& + P(t_j = v_1|t_i = v_1)\pi_i(t_j = v_1, {\scriptstyle\frac{v_0 + v_1}{2}}, \gamma^*(v_1)|t_i = v_1) = \frac{1}{2}\frac{v_1 - v_0}{2} + \frac{1}{2}\frac{v_1 - v_0}{2} = \frac{v_1 - v_0}{2}\\
		\mathbb{E}\pi_i(v_1|t_i = v_1)& = P(t_j = v_0|t_i = v_1)\pi_i(t_j = v_0, v_1, \gamma^*(v_0)|t_i = v_1) + P(t_j = v_1|t_i = v_1)\pi_i(t_j = v_1, v_1, \gamma^*(v_1)|t_i = v_1) = 0
	\end{split}
\end{equation}
Hence, indeed $\gamma^*(v_1) = v_0$ is part of the BNE.

Now, suppose $\gamma^*(v_1) = \frac{v_0 + v_1}{2}$. Then, $\forall i\in N$ and $j\neq i$
\begin{equation}
	\begin{split}
		\mathbb{E}\pi_i(v_0|t_i = v_1)& = P(t_j = v_0|t_i = v_1)\pi_i(t_j = v_0, v_0, \gamma^*(v_0)|t_i = v_1) + P(t_j = v_1|t_i = v_1)\pi_i(t_j = v_1, v_0, \gamma^*(v_1)|t_i = v_1)\\\nonumber
		& = \frac{1}{2}\frac{v_1 - v_0}{2} = \frac{v_1 - v_0}{4} \\
		\mathbb{E}\pi_i({\scriptstyle\frac{v_0 + v_1}{2}}|t_i = v_1)& = P(t_j = v_0|t_i = v_1)\pi_i(t_j = v_0, {\scriptstyle\frac{v_0 + v_1}{2}}, \gamma^*(v_0)|t_i = v_1)\\& + P(t_j = v_1|t_i = v_1)\pi_i(t_j = v_1, {\scriptstyle\frac{v_0 + v_1}{2}}, \gamma^*(v_1)|t_i = v_1) = \frac{1}{2}\frac{v_1 - v_0}{2} + \frac{1}{2}\frac{v_1 - v_0}{4} = \frac{3(v_1 - v_0)}{8}\\
		\mathbb{E}\pi_i(v_1|t_i = v_1)& = P(t_j = v_0|t_i = v_1)\pi_i(t_j = v_0, v_1, \gamma^*(v_0)|t_i = v_1) + P(t_j = v_1|t_i = v_1)\pi_i(t_j = v_1, v_1, \gamma^*(v_1)|t_i = v_1) = 0
	\end{split}
\end{equation}
Thus, $\gamma^*(v_1) = \frac{v_0 + v_1}{2}$ is also part of the BNE. More precisely, the set of BNE strategy profiles could be defined as $\{(v_0, v_0), (v_0, \frac{v_0 + v_1}{2})\}$.

\subsection*{Exercise 6}

The game could be represented as $SG = \{N, V, P, K, B, \{\pi_i\}_{i\in N}\}$, where
\begin{itemize}[label={}]
	\item $N = \{1, 2\}$ set of players;
	\item $V = \{v_l, v_r\}$ set of types of player 1 with $v_l$ standing for the left-hand side of the tree and $v_r$ - right-hand side of the tree;
	\item $P: V \to [0, 1], \qquad \begin{cases}
		v_l &\mapsto p \\
		v_r &\mapsto 1 - p
	\end{cases}$ probability distribution over types of player 1;
	\item $K = \{T, C\}$ set of messages player 1 can send;
	\item $B = \{A, M\}$ set of actions of player 2;
	\item $\pi_i: V\times K \times B\to \mathbb{R}$ payoffs $\forall i\in N$ as specified in the tree.
\end{itemize}

Define strategies of players 1 and 2 and belief of player 2 as follows:
\begin{equation}
	\begin{split}
		\gamma_1: V &\to \Delta(K), (v_l, v_r) \mapsto ((\gamma_{1l}(T), 1 - \gamma_{1l}(T)), (\gamma_{1r}(T), 1 - \gamma_{1r}(T))) \\
		\gamma_2: K &\to \Delta(B), (T, C) \mapsto ((\gamma_{2T}(A), 1 - \gamma_{2T}(A)), (\gamma_{2C}(A), 1 - \gamma_{2C}(A))) \\
		\mu: K &\to \Delta(V), (T, C) \mapsto ((q_1, 1 - q_1), (q_2, 1 - q_2)) \nonumber
	\end{split}
\end{equation}

There are \textbf{no separating equilibria} in this game.

Suppose otherwise and that $\gamma_{1l}(T) = 1$ and $\gamma_{1r}(T) = 0$. These strategies induce the following beliefs by Bayes Rule $\mu(T) = (1, 0)$ and $\mu(C) = (0, 1)$. Given such beliefs, optimal strategies of player 2 are $\gamma_2(T) = (0, 1)$ and $\gamma_2(C) = (1, 0)$. But, taking these strategies of player 2 as given, a strategy $\gamma_1(v_r) = (1, 0)$ is a profitable deviation for player 1 \Lightning.

Suppose $\gamma_{1l}(T) = 0$ and $\gamma_{1r}(T) = 1$. Given this strategies consistent beliefs could be pinned down by Bayes Rule to be $\mu(T) = (0, 1)$ and $\mu(C) = (1, 0)$. Taking these beliefs as given, optimal strategies for player 2 are $\gamma_2(T) = (1, 0)$ and $\gamma_2(C) = (0, 1)$. However, player 1's best response is then $\gamma_1(v_l) = (1, 0)$ and $\gamma_1(v_r) = (0, 1)$ \Lightning.

\textbf{Pooling equilibria}

In pooling equilibria, player 1 either chooses $T$ regardless of the type, or $C$ in both cases, or mixes between the two. However, notice that whenever type of player 1 is $v_l$, sending message $C$ is strictly dominated by $T$, regardless of the actions of player 2. Therefore, $\gamma_1^*(T) = (1, 0)$. 

Consider a subgame where player 2 observes message $T$, where the player chooses $A$ over $M$ if
\begin{equation}
	\begin{split}
		q_1 + 2(1 - q_1) &\geq 2q_1 + 1 - q_1 \\\nonumber
		q_1 &\leq \frac{1}{2}
	\end{split}
\end{equation}
Similarly, in a subgame where player 2 observed message $C$, he/she chooses $A$ over $M$ if
\begin{equation}
	\begin{split}
		q_2 + 2(1 - q_2) &\geq 2q_2 + 1 - q_2 \\ \nonumber
		q_2 &\leq \frac{1}{2}
	\end{split}
\end{equation}

Suppose system of beliefs is such that $q_1 \leq \frac{1}{2}$ and $q_2 \leq \frac{1}{2}$. Given such belief system, player 2 chooses $A$ in both information sets. Player 1's best response is $\gamma_1(v_l) = (1, 0)$ and $\gamma_1(v_r) = (1, 0)$. Given these strategies, any beliefs are consistent in the information set where player 2 gets message $C$ and $\mu(T) = (p, 1 - p)$ is statistically consistent. Hence, an assessment $(\gamma_1^* = ((1,0), (1, 0)), \gamma_2^* = ((1, 0), (1, 0)), \mu = ((p, 1 - p), (q_2, 1 - q_2)))$, where $q_2\leq\frac{1}{2}$ is WPBE if $p\leq\frac{1}{2}$.

Assume a system of beliefs such that $q_1 \leq \frac{1}{2}$ and $q_2 \geq \frac{1}{2}$. Given this belief system, $\gamma_2(T) = (1, 0)$ and $\gamma_2(C) = (0, 1)$. Then, player 1's best response is $\gamma_1(v_l) = (1, 0)$ and $\gamma_1(v_r) = (0, 1)$. Given this strategy profile, consistent beliefs are $\mu(T) = (1, 0)$ and $\mu(C) = (0, 1)$ \Lightning.

Assume a system of beliefs such that $q_1 \geq \frac{1}{2}$ and $q_2 \leq \frac{1}{2}$. Given this belief system, $\gamma_2(T) = (0, 1)$ and $\gamma_2(C) = (1, 0)$. Then, player 1's best response is $\gamma_1(v_l) = (1, 0)$ and $\gamma_1(v_r) = (1, 0)$. Given this strategy profile, any $q_2 \in [0, 1]$ are consistent because the information set where player 2 observes message $C$ is never reached. Bayes rule implies that consistent belief in the information set where player 2 observes message $T$ is $\mu(T) = (p, 1 - p)$. Hence, an assessment $(\gamma_1^* = ((1, 0), (1, 0)), \gamma_2^* = ((0, 1), (1, 0)), \mu = ((p, 1 - p), (q_2, 1 - q_2)))$, where $q_2\leq\frac{1}{2}$ is WPBE if $p\geq\frac{1}{2}$.

Assume a system of beliefs such that $q_1 \geq \frac{1}{2}$ and $q_2 \geq \frac{1}{2}$. Given this belief system, player 2 chooses $M$ in both information sets, i.e., $\gamma_2(T) = \gamma_2(C) = (0, 1)$. Then, player 1's best response is $\gamma_1(v_l) = (1, 0)$ and $\gamma_1(v_r) = (0, 1)$. Given this strategy profile, consistent beliefs are $\mu(T) = (1, 0)$ and $\mu(C) = (0, 1)$ \Lightning.

Assume $q_1 = \frac{1}{2}$ and $q_2 \leq \frac{1}{2}$. Given these beliefs, $\gamma_2(T) = (\varepsilon, 1 - \varepsilon)$, where $\varepsilon$ stands for the probability player 2 chooses $A$ when he/she receives message $T$ and $\gamma_2(C) = (1, 0)$. Then,
\begin{equation}
	\begin{split}
		\begin{matrix}
			\pi_1(T, \gamma_2^*|v_r) = 2 - \varepsilon \\ \nonumber
			\pi_1(C, \gamma_2^*|v_r) = 0
		\end{matrix} \Rightarrow \gamma_1(v_r) = (1, 0)
	\end{split}
\end{equation}
These strategies induce following beliefs $\mu(T) = (p, 1 - p), \mu(C) = (q_2, 1 - q_2), q_2\in [0, 1]$. Hence, an assessment $(\gamma_1^* = ((1, 0), (1, 0)), \gamma_2^* = ((\varepsilon, 1 - \varepsilon), (1, 0)), \mu = ((p, 1 - p), (q_2, 1 - q_2))| q_2\leq\frac{1}{2}, \varepsilon\in[0, 1])$ is a WPBE if $p = \frac{1}{2}$.

Assume $q_1 = \frac{1}{2}$ and $q_2 \geq \frac{1}{2}$. Given these beliefs, $\gamma_2(T) = (\varepsilon, 1 - \varepsilon)$ and $\gamma_2(C) = (0, 1)$. Then,
\begin{equation}
	\begin{split}
		\begin{matrix}
			\pi_1(T, \gamma_2^*|v_r) = 2 - \varepsilon \\ \nonumber
			\pi_1(C, \gamma_2^*|v_r) = 3
		\end{matrix} \Rightarrow \gamma_1(v_r) = (0, 1)
	\end{split}
\end{equation}
These strategies induce following beliefs $\mu(T) = (1, 0), \mu(C) = (0, 1)$ \Lightning.

Assume $q_1 \leq \frac{1}{2}$ and $q_2 = \frac{1}{2}$. Given these beliefs, $\gamma_2(T) = (1, 0)$ and $\gamma_2(C) = (\nu, 1 - \nu)$, where $\nu$ stands for the probability player 2 chooses $A$ when he/she receives message $C$. Then,
\begin{equation}
	\begin{split}
		\begin{matrix}
			\pi_1(T, \gamma_2^*|v_r) = 1 \\ \nonumber
			\pi_1(C, \gamma_2^*|v_r) = 3(1 - \nu)
		\end{matrix} \Rightarrow \gamma_1(v_r) = \begin{cases}
			(1, 0) & \text{ if } \nu > \frac{2}{3} \\
			(0, 1) & \text{ if } \nu < \frac{2}{3} \\
			(\varphi, 1 - \varphi), \varphi\in[0, 1] & \text{ if } \nu = \frac{2}{3}
		\end{cases} \\
		\Rightarrow \mu = \begin{cases}
			((p, 1 - p), (q_2, 1 - q_2)), q_2\in [0, 1] &\text{ if } \nu > \frac{2}{3}\\
			((1, 0), (0, 1)) &\text{ if } \nu < \frac{2}{3}\text{ \Lightning}\\
			((\frac{p}{p + (1 - p)\varphi}, \frac{(1 - p)\varphi}{p + (1 - p)\varphi}), (0, 1)) &\text{ if } \nu = \frac{2}{3}\text{ \Lightning}\\
		\end{cases}
	\end{split}
\end{equation}
Hence, an assessment $(\gamma_1^* = ((1, 0), (1, 0)), \gamma_2^* = ((1, 0), (\nu, 1 - \nu)), \mu = ((p, 1 - p), (\frac{1}{2}, \frac{1}{2}))| \nu > \frac{2}{3})$ is a WPBE if $p \leq \frac{1}{2}$.

Assume $q_1 \geq \frac{1}{2}$ and $q_2 = \frac{1}{2}$. Given these beliefs, $\gamma_2(T) = (0, 1)$ and $\gamma_2(C) = (\nu, 1 - \nu)$. Then,
\begin{equation}
	\begin{split}
		\begin{matrix}
			\pi_1(T, \gamma_2^*|v_r) = 2 \\ \nonumber
			\pi_1(C, \gamma_2^*|v_r) = 3(1 - \nu)
		\end{matrix} \Rightarrow \gamma_1(v_r) = \begin{cases}
			(1, 0) & \text{ if } \nu > \frac{1}{3} \\
			(0, 1) & \text{ if } \nu < \frac{1}{3} \\
			(\varphi, 1 - \varphi), \varphi\in[0, 1] & \text{ if } \nu = \frac{1}{3}
		\end{cases} \\
		\Rightarrow \mu = \begin{cases}
			((p, 1 - p), (q_2, 1 - q_2)), q_2\in [0, 1] &\text{ if } \nu > \frac{1}{3}\\
			((1, 0), (0, 1)) &\text{ if } \nu < \frac{1}{3}\text{ \Lightning}\\
			((\frac{p}{p + (1 - p)\varphi}, \frac{(1 - p)\varphi}{p + (1 - p)\varphi}), (0, 1)) &\text{ if } \nu = \frac{1}{3}\text{ \Lightning}\\
		\end{cases}
	\end{split}
\end{equation}
Hence, an assessment $(\gamma_1^* = ((1, 0), (1, 0)), \gamma_2^* = ((0, 1), (\nu, 1 - \nu)), \mu = ((p, 1 - p), (\frac{1}{2}, \frac{1}{2}))| \nu > \frac{1}{3})$ is a WPBE if $p \geq \frac{1}{2}$.

Assume $q_1 = q_2 = \frac{1}{2}$. Given these beliefs, $\gamma_2(T) = (\varepsilon, 1 - \varepsilon)$ and $\gamma_2(C) = (\nu, 1 - \nu)$. Then,
\begin{equation}
	\begin{split}
		\begin{matrix}
			\pi_1(T, \gamma_2^*|v_r) = 2 - \varepsilon \\ \nonumber
			\pi_1(C, \gamma_2^*|v_r) = 3(1 - \nu)
		\end{matrix} \Rightarrow \gamma_1(v_r) = \begin{cases}
			(1, 0) & \text{ if } 3\nu - \varepsilon > 1 \\
			(0, 1) & \text{ if } 3\nu - \varepsilon < 1 \\
			(\varphi, 1 - \varphi), \varphi\in[0, 1] & \text{ if } 3\nu - \varepsilon = 1
		\end{cases} \\
		\Rightarrow \mu = \begin{cases}
			((p, 1 - p), (q_2, 1 - q_2)), q_2\in [0, 1] &\text{ if } 3\nu - \varepsilon > 1 \\
			((1, 0), (0, 1)) &\text{ if } 3\nu - \varepsilon < 1\text{ \Lightning}\\
			((\frac{p}{p + (1 - p)\varphi}, \frac{(1 - p)\varphi}{p + (1 - p)\varphi}), (0, 1)) &\text{ if } 3\nu - \varepsilon = 1\text{ \Lightning}\\
		\end{cases}
	\end{split}
\end{equation}
Hence, an assessment $(\gamma_1^* = ((1, 0), (1, 0)), \gamma_2^* = ((\varepsilon, 1 - \varepsilon), (\nu, 1 - \nu)), \mu = ((p, 1 - p), (\frac{1}{2}, \frac{1}{2}))| 3\nu - \varepsilon > 1)$ is a WPBE if $p = \frac{1}{2}$.

Thus the set of pooling WPBE assessments is
\begin{equation}
	\begin{split}
	\begin{Bmatrix}
		(\gamma_1^* = ((1,0), (1, 0)), \gamma_2^* = ((1, 0), (1, 0)), \mu = ((p, 1 - p), (q_2, 1 - q_2))| q_2\leq\frac{1}{2}), \\
		(\gamma_1^* = ((1, 0), (1, 0)), \gamma_2^* = ((1, 0), (\nu, 1 - \nu)), \mu = ((p, 1 - p), (\frac{1}{2}, \frac{1}{2}))| \nu > \frac{2}{3})
	\end{Bmatrix}&\text{ if }p\leq\frac{1}{2} \\
	\begin{Bmatrix}
		(\gamma_1^* = ((1, 0), (1, 0)), \gamma_2^* = ((\varepsilon, 1 - \varepsilon), (1, 0)), \mu = ((p, 1 - p), (q_2, 1 - q_2))| q_2\leq\frac{1}{2}, \varepsilon\in[0, 1]), \\
		(\gamma_1^* = ((1, 0), (1, 0)), \gamma_2^* = ((\varepsilon, 1 - \varepsilon), (\nu, 1 - \nu)), \mu = ((p, 1 - p), (\frac{1}{2}, \frac{1}{2}))| 3\nu - \varepsilon > 1)
	\end{Bmatrix}&\text{ if }p = \frac{1}{2} \\
	\begin{Bmatrix}
		(\gamma_1^* = ((1, 0), (1, 0)), \gamma_2^* = ((0, 1), (1, 0)), \mu = ((p, 1 - p), (q_2, 1 - q_2))| q_2\leq\frac{1}{2}), \\
		(\gamma_1^* = ((1, 0), (1, 0)), \gamma_2^* = ((0, 1), (\nu, 1 - \nu)), \mu = ((p, 1 - p), (\frac{1}{2}, \frac{1}{2}))| \nu > \frac{1}{3})
	\end{Bmatrix}&\text{ if }p\geq\frac{1}{2} \nonumber
	\end{split}
\end{equation}

\end{document}
